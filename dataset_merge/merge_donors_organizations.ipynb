{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import unidecode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Merge past donors dataset (K4K sources) with donor organizations (PDF source)\n",
    "We will use the company name in both sources to try and match companies. We will use fuzzy matching so we can detect cases with similar strings (its likely names will have different versions in the sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors = pd.read_pickle('../Data/past_donors_clean.pickle')\n",
    "df_orgs = pd.read_excel('../Data/Organizations_stg.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col_names(df_):\n",
    "\n",
    "    df = df_.copy()\n",
    "    cols = df.columns.to_list()\n",
    "    new_cols=[]\n",
    "    for col in cols:\n",
    "        \n",
    "        col = re.sub(' +', ' ', col)\n",
    "        col = col.replace(' ','_')\n",
    "        col = col.replace('/','')\n",
    "        col = col.replace('$','dollar')\n",
    "        col = col.upper()\n",
    "        new_cols.append(col)\n",
    "\n",
    "    df.columns = new_cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors = clean_col_names(df_donors)\n",
    "df_orgs = clean_col_names(df_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stdr_names(series_original):\n",
    "    '''Clean company names. To be used in the different files so names are likelier to be matched'''\n",
    "    series = series_original.copy()\n",
    "    series = series.astype(str)\n",
    "    \n",
    "    series = series.str.upper()\n",
    "    series = series.str.strip()\n",
    "\n",
    "    series = series.replace(r'\\s+', ' ', regex=True)\n",
    "    series = series.str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "\n",
    "\n",
    "    series = series.apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "    series = series.str.replace(' QUEBEC ', '')\n",
    "    series = series.str.replace('CANADA', '')\n",
    "    series = series.str.replace(' MONTREAL ', '')\n",
    "    series = series.str.replace('MONTREAL ', '')\n",
    "    series = series.str.replace(' MONTREAL', '')\n",
    "    series = series.str.replace(' INC', '')\n",
    "    series = series.str.replace(' INC ', '')\n",
    "    series = series.str.replace(' CIE ', '')\n",
    "    series = series.str.replace(' CIE', '')\n",
    "    series = series.str.replace(' LTEE', '')\n",
    "    series = series.str.replace('CORPORATION', '')\n",
    "    series = series.str.replace('INTERNATIONAL', '')\n",
    "\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors = df_donors[ df_donors.COMPANY.notna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_orgs.NAME = stdr_names(df_orgs.NAME)\n",
    "\n",
    "df_donors.COMPANY = df_donors.COMPANY.astype(str)\n",
    "df_donors.COMPANY  = stdr_names(df_donors.COMPANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>COMPANY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARCHAMBAULT</td>\n",
       "      <td>ARCHAMBAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVERNA</td>\n",
       "      <td>AVERNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CANADIAN TIRE</td>\n",
       "      <td>CANADIAN TIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENTRES DENTAIRES LAPOINTE</td>\n",
       "      <td>CENTRES DENTAIRES LAPOINTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CGI</td>\n",
       "      <td>CGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CORBEC</td>\n",
       "      <td>CORBEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DORFIN</td>\n",
       "      <td>DORFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENERGIE CARDIO</td>\n",
       "      <td>ENERGIE CARDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FIERA CAPITAL</td>\n",
       "      <td>FIERA CAPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FUTURE SHOP</td>\n",
       "      <td>FUTURE SHOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JEAN COUTU</td>\n",
       "      <td>JEAN COUTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KRUGER</td>\n",
       "      <td>KRUGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LABORATOIRES CHARLES RIVER</td>\n",
       "      <td>LABORATOIRES CHARLES RIVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LASSONDE</td>\n",
       "      <td>LASSONDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MAXI</td>\n",
       "      <td>MAXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROYAL LEPAGE</td>\n",
       "      <td>ROYAL LEPAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ULTRAMAR</td>\n",
       "      <td>ULTRAMAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WESTJET</td>\n",
       "      <td>WESTJET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          NAME                     COMPANY\n",
       "0                  ARCHAMBAULT                 ARCHAMBAULT\n",
       "1                       AVERNA                      AVERNA\n",
       "2                CANADIAN TIRE               CANADIAN TIRE\n",
       "3   CENTRES DENTAIRES LAPOINTE  CENTRES DENTAIRES LAPOINTE\n",
       "4                          CGI                         CGI\n",
       "5                       CORBEC                      CORBEC\n",
       "6                       DORFIN                      DORFIN\n",
       "7               ENERGIE CARDIO              ENERGIE CARDIO\n",
       "8                FIERA CAPITAL               FIERA CAPITAL\n",
       "9                  FUTURE SHOP                 FUTURE SHOP\n",
       "10                  JEAN COUTU                  JEAN COUTU\n",
       "11                      KRUGER                      KRUGER\n",
       "12  LABORATOIRES CHARLES RIVER  LABORATOIRES CHARLES RIVER\n",
       "13                    LASSONDE                    LASSONDE\n",
       "14                        MAXI                        MAXI\n",
       "15                ROYAL LEPAGE                ROYAL LEPAGE\n",
       "16                    ULTRAMAR                    ULTRAMAR\n",
       "17                     WESTJET                     WESTJET"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_orgs.NAME.drop_duplicates(), df_donors.COMPANY.drop_duplicates(), left_on='NAME', right_on='COMPANY')\n",
    "\n",
    "# 18 matches by exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/tutorial/fuzzy-string-python\n",
    "\n",
    "\n",
    "# this for-loop calculates 4 kinds of similarity score, which we will then use to sort the table and manually review the most similar matches to confirm (based on K4K feedback)\n",
    "\n",
    "def match_comp_names(orgs, donors):\n",
    "\n",
    "    # orgs = orgs.NAME.drop_duplicates().to_list()\n",
    "    # donors = donors.company.drop_duplicates().to_list()\n",
    "\n",
    "    d = 0\n",
    "    j = 0\n",
    "    rows = []\n",
    "\n",
    "    for org in orgs:\n",
    "        for donor in donors:\n",
    "            Str1 = org\n",
    "            Str2 = donor\n",
    "            Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "            Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "            Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "            Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "\n",
    "            row = [org, donor, Ratio, Partial_Ratio, Token_Sort_Ratio, Token_Set_Ratio]\n",
    "\n",
    "            rows.append(row)\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\OneDrive - McGill University\\Summer Term 2022\\Community Capstone\\Kurling4Kids\\dataset_merge\\merge_donors_organizations.ipynb Celda 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=0'>1</a>\u001b[0m rows \u001b[39m=\u001b[39m match_comp_names(df_orgs\u001b[39m.\u001b[39;49mNAME\u001b[39m.\u001b[39;49mdrop_duplicates()\u001b[39m.\u001b[39;49mto_list(), df_donors\u001b[39m.\u001b[39;49mcompany\u001b[39m.\u001b[39;49mdrop_duplicates()\u001b[39m.\u001b[39;49mto_list())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=1'>2</a>\u001b[0m df_sim \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(rows, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39morg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdonor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRatio\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPartial_Ratio\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mToken_Sort_Ratio\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mToken_Set_Ratio\u001b[39m\u001b[39m'\u001b[39m] )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=2'>3</a>\u001b[0m df_sim\u001b[39m.\u001b[39mto_pickle(\u001b[39m'\u001b[39m\u001b[39msimilarity_score.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\carlo\\OneDrive - McGill University\\Summer Term 2022\\Community Capstone\\Kurling4Kids\\dataset_merge\\merge_donors_organizations.ipynb Celda 9\u001b[0m in \u001b[0;36mmatch_comp_names\u001b[1;34m(orgs, donors)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=18'>19</a>\u001b[0m Ratio \u001b[39m=\u001b[39m fuzz\u001b[39m.\u001b[39mratio(Str1\u001b[39m.\u001b[39mlower(),Str2\u001b[39m.\u001b[39mlower())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=19'>20</a>\u001b[0m Partial_Ratio \u001b[39m=\u001b[39m fuzz\u001b[39m.\u001b[39mpartial_ratio(Str1\u001b[39m.\u001b[39mlower(),Str2\u001b[39m.\u001b[39mlower())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=20'>21</a>\u001b[0m Token_Sort_Ratio \u001b[39m=\u001b[39m fuzz\u001b[39m.\u001b[39;49mtoken_sort_ratio(Str1,Str2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=21'>22</a>\u001b[0m Token_Set_Ratio \u001b[39m=\u001b[39m fuzz\u001b[39m.\u001b[39mtoken_set_ratio(Str1,Str2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/OneDrive%20-%20McGill%20University/Summer%20Term%202022/Community%20Capstone/Kurling4Kids/dataset_merge/merge_donors_organizations.ipynb#ch0000008?line=23'>24</a>\u001b[0m row \u001b[39m=\u001b[39m [org, donor, Ratio, Partial_Ratio, Token_Sort_Ratio, Token_Set_Ratio]\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:105\u001b[0m, in \u001b[0;36mtoken_sort_ratio\u001b[1;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtoken_sort_ratio\u001b[39m(s1, s2, force_ascii\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, full_process\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\"\"Return a measure of the sequences' similarity between 0 and 100\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m    but sorting the token before comparing.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m _token_sort(s1, s2, partial\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, force_ascii\u001b[39m=\u001b[39;49mforce_ascii, full_process\u001b[39m=\u001b[39;49mfull_process)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:98\u001b[0m, in \u001b[0;36m_token_sort\u001b[1;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m partial_ratio(sorted1, sorted2)\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m ratio(sorted1, sorted2)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\utils.py:29\u001b[0m, in \u001b[0;36mcheck_for_equivalence.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m args[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m100\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\utils.py:47\u001b[0m, in \u001b[0;36mcheck_empty_string.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args[\u001b[39m0\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(args[\u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:28\u001b[0m, in \u001b[0;36mratio\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m     25\u001b[0m s1, s2 \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmake_type_consistent(s1, s2)\n\u001b[0;32m     27\u001b[0m m \u001b[39m=\u001b[39m SequenceMatcher(\u001b[39mNone\u001b[39;00m, s1, s2)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39mintr(\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m m\u001b[39m.\u001b[39;49mratio())\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\difflib.py:644\u001b[0m, in \u001b[0;36mSequenceMatcher.ratio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mratio\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    623\u001b[0m     \u001b[39m\"\"\"Return a measure of the sequences' similarity (float in [0,1]).\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \n\u001b[0;32m    625\u001b[0m \u001b[39m    Where T is the total number of elements in both sequences, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39m    1.0\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m     matches \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(triple[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m triple \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_matching_blocks())\n\u001b[0;32m    645\u001b[0m     \u001b[39mreturn\u001b[39;00m _calculate_ratio(matches, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb))\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\difflib.py:479\u001b[0m, in \u001b[0;36mSequenceMatcher.get_matching_blocks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mwhile\u001b[39;00m queue:\n\u001b[0;32m    478\u001b[0m     alo, ahi, blo, bhi \u001b[39m=\u001b[39m queue\u001b[39m.\u001b[39mpop()\n\u001b[1;32m--> 479\u001b[0m     i, j, k \u001b[39m=\u001b[39m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_longest_match(alo, ahi, blo, bhi)\n\u001b[0;32m    480\u001b[0m     \u001b[39m# a[alo:i] vs b[blo:j] unknown\u001b[39;00m\n\u001b[0;32m    481\u001b[0m     \u001b[39m# a[i:i+k] same as b[j:j+k]\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[39m# a[i+k:ahi] vs b[j+k:bhi] unknown\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m k:   \u001b[39m# if k is 0, there was no matching block\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\lib\\difflib.py:402\u001b[0m, in \u001b[0;36mSequenceMatcher.find_longest_match\u001b[1;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[0;32m    398\u001b[0m nothing \u001b[39m=\u001b[39m []\n\u001b[0;32m    399\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(alo, ahi):\n\u001b[0;32m    400\u001b[0m     \u001b[39m# look at all instances of a[i] in b; note that because\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[39m# b2j has no junk keys, the loop is skipped if a[i] is junk\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     j2lenget \u001b[39m=\u001b[39m j2len\u001b[39m.\u001b[39;49mget\n\u001b[0;32m    403\u001b[0m     newj2len \u001b[39m=\u001b[39m {}\n\u001b[0;32m    404\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m b2j\u001b[39m.\u001b[39mget(a[i], nothing):\n\u001b[0;32m    405\u001b[0m         \u001b[39m# a[i] matches b[j]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rows = match_comp_names(df_orgs.NAME.drop_duplicates().to_list(), df_donors.COMPANY.drop_duplicates().to_list())\n",
    "df_sim = pd.DataFrame(rows, columns = ['org', 'donor', 'Ratio', 'Partial_Ratio', 'Token_Sort_Ratio', 'Token_Set_Ratio'] )\n",
    "df_sim.to_pickle('similarity_score.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'Ratio'\n",
    "df_ratios = df_sim.groupby('org', as_index=False)[score].max()\n",
    "#df_ratios.merge(df_sim[['org', 'donor', score]], how = 'inner').sort_values(score, ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'Token_Set_Ratio'\n",
    "\n",
    "df_ratios = df_sim.groupby('donor', as_index=False)[score].max()\n",
    "#df_token_set_ratio = df_ratios.merge(df_sim[['org', 'donor', score]], how = 'inner').sort_values(score, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'Partial_Ratio'\n",
    "#df_ratios = df_sim.groupby('org', as_index=False)[score].max()\n",
    "#df_ratios.merge(df_sim[['org', 'donor', score]], how = 'inner').sort_values(score, ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org</th>\n",
       "      <th>Token_Sort_Ratio</th>\n",
       "      <th>donor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>KRUGER</td>\n",
       "      <td>100</td>\n",
       "      <td>KRUGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>CORBEC</td>\n",
       "      <td>100</td>\n",
       "      <td>CORBEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>ROYAL LEPAGE</td>\n",
       "      <td>100</td>\n",
       "      <td>ROYAL LEPAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>LABORATOIRES CHARLES RIVER</td>\n",
       "      <td>100</td>\n",
       "      <td>LABORATOIRES CHARLES RIVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>DELMAR</td>\n",
       "      <td>100</td>\n",
       "      <td>DELMAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>FUTURE SHOP</td>\n",
       "      <td>100</td>\n",
       "      <td>FUTURE SHOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>JEAN COUTU</td>\n",
       "      <td>100</td>\n",
       "      <td>JEAN COUTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>BDO</td>\n",
       "      <td>100</td>\n",
       "      <td>BDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>CANADIAN TIRE</td>\n",
       "      <td>100</td>\n",
       "      <td>CANADIAN TIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>SNC  LAVALIN</td>\n",
       "      <td>100</td>\n",
       "      <td>SNC LAVALIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>LASSONDE</td>\n",
       "      <td>100</td>\n",
       "      <td>LASSONDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>AVERNA</td>\n",
       "      <td>100</td>\n",
       "      <td>AVERNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>ULTRAMAR</td>\n",
       "      <td>100</td>\n",
       "      <td>ULTRAMAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>DORFIN</td>\n",
       "      <td>100</td>\n",
       "      <td>DORFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>ARCHAMBAULT</td>\n",
       "      <td>100</td>\n",
       "      <td>ARCHAMBAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>UPS</td>\n",
       "      <td>100</td>\n",
       "      <td>UPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>MERCER</td>\n",
       "      <td>100</td>\n",
       "      <td>MERCER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>FIERA CAPITAL</td>\n",
       "      <td>100</td>\n",
       "      <td>FIERA CAPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>ENERGIE CARDIO</td>\n",
       "      <td>100</td>\n",
       "      <td>ENERGIE CARDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>WESTJET</td>\n",
       "      <td>100</td>\n",
       "      <td>WESTJET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             org  Token_Sort_Ratio                       donor\n",
       "1317                      KRUGER               100                      KRUGER\n",
       "846                       CORBEC               100                      CORBEC\n",
       "1772                ROYAL LEPAGE               100                ROYAL LEPAGE\n",
       "1329  LABORATOIRES CHARLES RIVER               100  LABORATOIRES CHARLES RIVER\n",
       "881                       DELMAR               100                     DELMAR \n",
       "1061                 FUTURE SHOP               100                 FUTURE SHOP\n",
       "1278                  JEAN COUTU               100                  JEAN COUTU\n",
       "613                         BDO                100                         BDO\n",
       "733                CANADIAN TIRE               100               CANADIAN TIRE\n",
       "1832                SNC  LAVALIN               100                 SNC LAVALIN\n",
       "1350                    LASSONDE               100                    LASSONDE\n",
       "580                       AVERNA               100                      AVERNA\n",
       "1989                    ULTRAMAR               100                    ULTRAMAR\n",
       "928                       DORFIN               100                      DORFIN\n",
       "556                  ARCHAMBAULT               100                 ARCHAMBAULT\n",
       "1997                        UPS                100                         UPS\n",
       "1484                     MERCER                100                      MERCER\n",
       "1025               FIERA CAPITAL               100               FIERA CAPITAL\n",
       "971               ENERGIE CARDIO               100              ENERGIE CARDIO\n",
       "2054                     WESTJET               100                     WESTJET"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "score = 'Token_Sort_Ratio'\n",
    "\n",
    "df_ratios = df_sim.groupby('org', as_index=False)[score].max()\n",
    "df_ratios.merge(df_sim[['org', 'donor', score]], how = 'inner').sort_values(score, ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort the values and export them to CSV so we can review in excel\n",
    "\n",
    "th = 70\n",
    "df_filt = df_sim.query(f''' Ratio > {th} |  Token_Sort_Ratio > {th}  | Token_Set_Ratio > {th}  ''' ).reset_index(drop=True)\n",
    "df_filt.shape\n",
    "df_filt.sort_values(['Token_Set_Ratio', 'Ratio'], ascending=False).to_clipboard(index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confirm matches based on reviewed excel\n",
    "After manually confirming the fuzzy matching scores, we will produces the final merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "def clean_col_names(df_):\n",
    "\n",
    "    df = df_.copy()\n",
    "    cols = df.columns.to_list()\n",
    "    new_cols=[]\n",
    "    for col in cols:\n",
    "        \n",
    "        col = re.sub(' +', ' ', col)\n",
    "        col = col.replace(' ','_')\n",
    "        col = col.replace('/','')\n",
    "        col = col.replace('$','dollar')\n",
    "        col = col.upper()\n",
    "        new_cols.append(col)\n",
    "\n",
    "    df.columns = new_cols\n",
    "\n",
    "    return df\n",
    "    \n",
    "def stdr_names(series_original):\n",
    "    '''Clean company names. To be used in the different files so names are likelier to be matched'''\n",
    "    series = series_original.copy()\n",
    "    series = series.astype(str)\n",
    "    \n",
    "    series = series.str.upper()\n",
    "    series = series.str.strip()\n",
    "\n",
    "    series = series.replace(r'\\s+', ' ', regex=True)\n",
    "    series = series.str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "\n",
    "\n",
    "    series = series.apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "    series = series.str.replace(' QUEBEC ', '')\n",
    "    series = series.str.replace('CANADA', '')\n",
    "    series = series.str.replace(' MONTREAL ', '')\n",
    "    series = series.str.replace('MONTREAL ', '')\n",
    "    series = series.str.replace(' MONTREAL', '')\n",
    "    series = series.str.replace(' INC', '')\n",
    "    series = series.str.replace(' INC ', '')\n",
    "    series = series.str.replace(' CIE ', '')\n",
    "    series = series.str.replace(' CIE', '')\n",
    "    series = series.str.replace(' LTEE', '')\n",
    "    series = series.str.replace('CORPORATION', '')\n",
    "    series = series.str.replace('INTERNATIONAL', '')\n",
    "\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors = pd.read_csv('../Data/past_donors_clean.csv', parse_dates=[1])\n",
    "df_orgs = pd.read_excel('../Data/Organizations_stg.xlsx')\n",
    "\n",
    "df_donors=clean_col_names(df_donors)\n",
    "df_orgs=clean_col_names(df_orgs)\n",
    "\n",
    "# now we read the matches after reviews them and this will become our key to match both sources\n",
    "df_matches = pd.read_excel('../Data/matched_orgs_k4kreview.xlsx')\n",
    "\n",
    "df_donors.COMPANY = stdr_names(df_donors.COMPANY)\n",
    "df_orgs.NAME = stdr_names(df_orgs.NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = df_matches[df_matches.Match == 1] # keeping only matches\n",
    "df_matches = df_matches.iloc[:, 0:2]\n",
    "df_matches.columns = ['ORGANIZATION', 'DONOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some past donors have been matched with more than 1 different company in the PDF source, so we need to select and keep only one so the analysis is consistent.\n",
    "donor_q = df_matches.DONOR.value_counts()\n",
    "organization_q = df_matches.ORGANIZATION.value_counts()\n",
    "df1 = df_matches[df_matches.DONOR.isin(donor_q[donor_q > 1].index)].sort_values('DONOR').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ixs = [1, 2,5,6,10,11,15,16,18, 21,22] \n",
    "df1 = df1.iloc[ixs,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we concatenate the matches into a single df\n",
    "df_matches = pd.concat([ df_matches[df_matches.DONOR.isin(donor_q[donor_q <= 1].index)].sort_values('DONOR').reset_index(drop=True),\n",
    "            df1 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors_match = df_donors.merge(df_matches, how = 'inner', left_on = 'COMPANY', right_on = 'DONOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors_match = df_donors_match.merge(df_orgs, how = 'inner', left_on = 'ORGANIZATION', right_on = 'NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors_match = df_donors_match.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_donors_match.shape\n",
    "\n",
    "# after matching past donors and organizations PDF, we have 177 rows of data and 32 columns. We should add additiional attributes of the companies that have foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding foundation attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fonds = pd.read_excel('../Data/Foundations_stg.xlsx')\n",
    "\n",
    "df_fonds = clean_col_names(df_fonds)\n",
    "\n",
    "## add foundations dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 85)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_donors_match.merge(df_fonds, how='left', on='ID', suffixes=('', '_FND'))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obviously, most companies will have null values in their foundation attributes, but we can still keep the info for the ones that do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../Data/df_matches.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COMPANY', 'ADDED_MODIFIED', 'DOLLAR_AMOUNT_FLOAT',\n",
       "       'MONEYPRIZE_RECEIVED', 'DONATION_DETAILS', 'YEAR', 'DON_DETAIL_AMOUNT',\n",
       "       'DOLLAR_EQUIVALENT_AMOUNT', 'DON_DETAIL_TXT', 'ORGANIZATION', 'DONOR',\n",
       "       'ID', '2E_CONTACT_POUR', 'ADDRESS', 'AVIS', 'CONTACT', 'CONTRIBUTION',\n",
       "       'COURRIEL', 'DDD', 'DOMAINE_DINTERET', 'FAF', 'FAX', 'FILIALE_DE',\n",
       "       'ISFOUNDATION', 'LANGUE', 'LIMITES_GEOG', 'N_DE_TEL', 'NAME',\n",
       "       'NBRE_DE_SUCC', 'NOMBRE_DEMPLOYES', 'NOTE', 'POSTE', 'PRINCIP_FILIALES',\n",
       "       'SECTEUR_INDUSTRIEL', 'SITE_WEB', 'MUNICIPALITY', 'PROVINCE',\n",
       "       'POSTALCODE', 'STREET', 'SECTOR_FABRICATION', 'SECTOR_FINANCIERS',\n",
       "       'SECTOR_COMMERCE', 'SECTOR_CONSTRUCTION', 'SECTOR_TRANSPORT',\n",
       "       'SECTOR_GESTION', 'SECTOR_SYSTEMS', 'SECTOR_ALIMENTATION',\n",
       "       'SECTOR_SANTE_ASSURANCE', 'SECTOR_OTHER', 'GENERAL_CHARITY',\n",
       "       'HEALTH_ARTS_CULTURE', 'COMMUNITY_ENVIRONMENTAL',\n",
       "       'YOUTH_HEALTH_EDUCATION', 'REGIONAL_SPECIFIC',\n",
       "       'CANCER_DISEASE_RESEARCH', 'INTEREST_DOMAIN_CLEAN', 'MAIN_TOPIC',\n",
       "       'MAIN_TOPIC_SCORE', 'SECONDARY_TOPIC', 'SECONDARY_TOPIC_SCR', 'ACTIF',\n",
       "       'ADDRESS_FND', 'AVIS_FND', 'CATEGORIE', 'CONTACT_FND', 'COURRIEL_FND',\n",
       "       'DATE_APPROB', 'DATE_FIN_DANN', 'DOMAINES_DINTERET', 'ECHELLEDONS',\n",
       "       'ISFOUNDATION_FND', 'LANGUE_FND', 'LIMITES_GEOG_FND', 'N_DE_TEL_FND',\n",
       "       'NAME_FND', 'OU', 'POSTE_FND', 'PROJETS_PRIVILEGIES', 'TEL',\n",
       "       'TOTAL_ANNUEL', 'WEB', 'MUNICIPALITY_FND', 'PROVINCE_FND',\n",
       "       'POSTALCODE_FND', 'STREET_FND'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e76f8642360a3358ab06c318ab18c1161224eb3836609d5c16edea6f6e43dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
